
configfile: os.path.join(workflow.basedir, '../', 'config', 'config.yaml')

# Concatenate Snakemake's own log file with the master log file
onsuccess:
    shell("cat {log} >> " + config['log'])

onerror:
    shell("cat {log} >> " + config['log'])

outTouch = os.path.join(config['output'], config['input'])

### DEFAULT CONFIG FILE
configfile: os.path.join(workflow.basedir, '../', 'config', 'config.yaml')

CSV = config['input']
OUTPUT = config['output']
THREADS = config['threads']
SHORT_READS = config['short_reads']

# flye params
FLYE_MODEL = config["flyeModel"]

# snakemake params 
MassiveJobMem = config["BigJobMem"]
BigJobMem = config["BigJobMem"]
BigJobCpu = config["BigJobCpu"]
SmallJobMem = config["SmallJobMem"]
SmallJobCpu = config["SmallJobCpu"]

SmallTime = config["SmallTime"]
BigTime = config["BigTime"]
MediumTime = config["MediumTime"]
MassiveTime = config["MassiveTime"]

###### define the species for transcriptome
Reference = config['reference']


# need to specify the reads directory
CSV = config['input']

# define functions
def get_input_lr_fastqs(wildcards):
    return dictReads[wildcards.sample]["LR"]

def get_input_r1_fastqs(wildcards):
    return dictReads[wildcards.sample]["R1"]

def get_input_r2_fastqs(wildcards):
    return dictReads[wildcards.sample]["R2"]

### DIRECTORIES
include: "rules/directories.smk"

# Parse the samples and read files
include: "rules/samples.smk"

print(SHORT_READS)
if SHORT_READS == True:
    dictReads = parseSamplesShort(CSV)
    SAMPLES = list(dictReads.keys())
else:
    dictReads = parseSamples(CSV)
    SAMPLES = list(dictReads.keys())


    samplesFromCsvNanopore

# wildcard constraints
wildcard_constraints:
    sample= '|'.join([re.escape(x) for x in SAMPLES])


# Import rules and functions
include: "rules/targets.smk"
include: "rules/align.smk"
include: "rules/assemble.smk"


rule all:
    input:
        TargetFiles
        